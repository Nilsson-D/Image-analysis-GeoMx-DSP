{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of calssification/segmentation models\n",
    "\n",
    "This jupyter notebook is used to calculate the f1-score, accuracy, precision and recall. It is based on the segmentation masks and the class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import skimage\n",
    "import json\n",
    "import os\n",
    "import glob as glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_bounding_boxes_and_labels(labeled_image, label_dict):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        labeled_image (_type_): labeled image as numpy array\n",
    "        label_dict (_type_): class dictionary from Qupath\n",
    "\n",
    "    Returns:\n",
    "        _type_: bounding boxes of each object and it's label\n",
    "    \"\"\"\n",
    "    objects = scipy.ndimage.find_objects(labeled_image)\n",
    "    bounding_boxes = []\n",
    "    labels = []\n",
    "    \n",
    "    for obj_id, obj_slice in enumerate(objects):\n",
    "        if obj_slice is not None:\n",
    "            ymin, xmin, ymax, xmax = obj_slice[0].start, obj_slice[1].start, obj_slice[0].stop, obj_slice[1].stop\n",
    "            bounding_boxes.append((xmin, ymin, xmax - xmin, ymax - ymin))  # Format: (x, y, width, height)\n",
    "            for class_label, ids in label_dict.items():\n",
    "                if obj_id + 1 in ids:  # labels start from 1\n",
    "                    labels.append(class_label)\n",
    "                    break\n",
    "            else:\n",
    "                labels.append('unknown')  # If not found in any class\n",
    "    return bounding_boxes, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(box1, box2):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        box1 (_type_): bounding box of first object\n",
    "        box2 (_type_): bounding box of second object\n",
    "\n",
    "    Returns:\n",
    "        _type_: intersection over union\n",
    "    \"\"\"\n",
    "    \n",
    "    #get coordinates\n",
    "    x_left = max(box1[0], box2[0])\n",
    "    y_top = max(box1[1], box2[1])\n",
    "    x_right = min(box1[0] + box1[2], box2[0] + box2[2])\n",
    "    y_bottom = min(box1[1] + box1[3], box2[1] + box2[3])\n",
    "\n",
    "    #if not overlapping\n",
    "    if x_right < x_left or y_bottom < y_top:\n",
    "        return 0.0\n",
    "\n",
    "    #get intersection\n",
    "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "    #get area of the boxes\n",
    "    box1_area = box1[2] * box1[3]\n",
    "    box2_area = box2[2] * box2[3]\n",
    "    #calculated the union\n",
    "    union_area = box1_area + box2_area - intersection_area\n",
    "    #calculate the iou\n",
    "    iou = intersection_area / union_area\n",
    "    return iou\n",
    "\n",
    "def evaluate_detection(pred_boxes, pred_labels, gt_boxes, gt_labels, iou_threshold=0.5):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        pred_boxes (_type_): bounding box of prediction\n",
    "        pred_labels (_type_): predicted label\n",
    "        gt_boxes (_type_): bounding box of ground truth\n",
    "        gt_labels (_type_): ground truth label\n",
    "        iou_threshold (float, optional): IoU threshold. Defaults to 0.5.\n",
    "\n",
    "    Returns:\n",
    "        _type_: tuple with tp, fp, fn\n",
    "    \"\"\"\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    matched_gt = []\n",
    "\n",
    "    for pred_box, pred_label in zip(pred_boxes, pred_labels):\n",
    "        best_iou = 0\n",
    "        best_gt_idx = None\n",
    "        for gt_idx, (gt_box, gt_label) in enumerate(zip(gt_boxes, gt_labels)):\n",
    "            if gt_idx in matched_gt: #count only once\n",
    "                continue\n",
    "            iou = compute_iou(pred_box, gt_box) #compute iou\n",
    "            if iou > best_iou: #check for best overlap\n",
    "                best_iou = iou\n",
    "                best_gt_idx = gt_idx\n",
    "        \n",
    "        if best_iou >= iou_threshold and pred_label == gt_labels[best_gt_idx]: #check for iou over threshold and correct label\n",
    "            tp += 1\n",
    "            matched_gt.append(best_gt_idx)\n",
    "        else:\n",
    "            fp += 1\n",
    "    \n",
    "    fn = len(gt_boxes) - len(matched_gt)\n",
    "\n",
    "    return tp, fp, fn\n",
    "\n",
    "def aggregate_metrics(results):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        results (_type_): dictionary with tp, fp and fn\n",
    "\n",
    "    Returns:\n",
    "        _type_: a dictionary with calculated metrics: tp, fp, fn, f1-score, accuracy, precision and recall\n",
    "    \"\"\"\n",
    "    tp = sum([result['tp'] for result in results])\n",
    "    fp = sum([result['fp'] for result in results])\n",
    "    fn = sum([result['fn'] for result in results])\n",
    "\n",
    "    \n",
    "    precision = tp / (tp + fp) if tp + fp > 0 else 0\n",
    "    recall = tp / (tp + fn) if tp + fn > 0 else 0\n",
    "    accuracy = tp / (tp + fp + fn) if tp + fp + fn > 0 else 0\n",
    "    f1_score = 2 * precision * recall / (precision + recall) if precision + recall > 0 else 0\n",
    "\n",
    "    return {\n",
    "        'tp': tp,\n",
    "        'fp': fp,\n",
    "        'fn': fn,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#This function does the same as the above but here I also confirm that the scipys order of objects match the actual label id in the image assigned by qupath \n",
    "def extract_bounding_boxes_and_labels(labeled_image, label_dict):\n",
    "    objects = scipy.ndimage.find_objects(labeled_image)\n",
    "    labeled_image = labeled_image.astype(np.int32)\n",
    "    bounding_boxes = []\n",
    "    labels = []\n",
    "    \n",
    "    # Invert the label_dict to map object IDs to class labels\n",
    "    inverted_label_dict = {}\n",
    "    for class_label, ids in label_dict.items():\n",
    "        for obj_id in ids:\n",
    "            inverted_label_dict[obj_id] = class_label\n",
    "    \n",
    "    for obj_id, obj_slice in enumerate(objects, 1):\n",
    "        if obj_slice is not None:\n",
    "            ymin, xmin, ymax, xmax = obj_slice[0].start, obj_slice[1].start, obj_slice[0].stop, obj_slice[1].stop\n",
    "            bbox = (xmin, ymin, xmax - xmin, ymax - ymin)  # Format: (x, y, width, height)\n",
    "            sub_image = labeled_image[ymin:ymax, xmin:xmax]\n",
    "            unique_ids, counts = np.unique(sub_image, return_counts=True)\n",
    "            # Filter out background\n",
    "            mask = unique_ids != 0\n",
    "            unique_ids = unique_ids[mask]\n",
    "            counts = counts[mask]\n",
    "            if len(counts) == 0:\n",
    "                continue  # Skip if no valid objects\n",
    "            dominant_id = unique_ids[np.argmax(counts)]\n",
    "            assert obj_id == dominant_id\n",
    "            label = inverted_label_dict.get(dominant_id, 'unknown')\n",
    "            bounding_boxes.append(bbox)\n",
    "            labels.append(label)\n",
    "    \n",
    "    return bounding_boxes, labels\n",
    "\n",
    "def process_image_folder(pred_folder, gt_folder, i):\n",
    "    \"\"\"Process the folder of images to be used for evaluation. \n",
    "\n",
    "    Args:\n",
    "        pred_folder (_type_): folder to predicted masks and classes\n",
    "        gt_folder (_type_): folder to ground truth masks and classes\n",
    "        i (_type_): roi number from QuPath (if more than one roi per image, we need to handle these indivdually)\n",
    "\n",
    "    Returns:\n",
    "        _type_: summarized metrics\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    pred_files = glob.glob(os.path.join(pred_folder, f\"*{i}-labels.tiff\"))\n",
    "    gt_files = glob.glob(os.path.join(gt_folder, f\"*{i}-labels.tiff\"))\n",
    "\n",
    "    for pred_filepath,gt_filepath in zip(pred_files,gt_files):\n",
    "        # Extract base name without the digit and -labels.tiff\n",
    "        base_name_match = re.match(r'(.+)-labels\\.tiff$', os.path.basename(pred_filepath))\n",
    "\n",
    "        base_name = base_name_match.group(1)[:-2]\n",
    "\n",
    "        \n",
    "        pred_json_path = os.path.join(pred_folder, f\"{base_name}-classmap.json\")\n",
    "        gt_json_path = os.path.join(gt_folder, f\"{base_name}-classmap.json\")\n",
    "        \n",
    "        if os.path.exists(gt_filepath) and os.path.exists(pred_json_path) and os.path.exists(gt_json_path):\n",
    "            pred_labeled_image = skimage.io.imread(pred_filepath)\n",
    "            gt_labeled_image = skimage.io.imread(gt_filepath)\n",
    "            \n",
    "            with open(pred_json_path, 'r') as f:\n",
    "                pred_label_dict = json.load(f)\n",
    "\n",
    "            with open(gt_json_path, 'r') as f:\n",
    "                gt_label_dict = json.load(f)\n",
    "\n",
    "            pred_boxes, pred_labels = extract_bounding_boxes_and_labels(pred_labeled_image, pred_label_dict)\n",
    "            gt_boxes, gt_labels = extract_bounding_boxes_and_labels(gt_labeled_image, gt_label_dict)\n",
    "\n",
    "            tp, fp, fn = evaluate_detection(pred_boxes, pred_labels, gt_boxes, gt_labels)\n",
    "            results.append({'tp': tp, 'fp': fp, 'fn': fn})\n",
    "\n",
    "    return aggregate_metrics(results)\n",
    "\n",
    "cellpose_fineTuned_metrics_dict = dict()\n",
    "cellpose_unTuned_metrics_dict = dict()\n",
    "QuPath_RF_metrics_dict = dict()\n",
    "for i in range(1, 3):\n",
    "    print(f\"Metrics for images with ROIs with nr {i}\")\n",
    "    gt_folder = \"Ground_Truth folder\"\n",
    "    pred_folder = \"Cellpose_FineTuned folder\"\n",
    "    cellpose_fineTuned_metrics_dict[i] = process_image_folder(pred_folder, gt_folder,i)\n",
    "    print(f\"Cellpose  finetuned: {cellpose_fineTuned_metrics_dict[i]}\")\n",
    "\n",
    "\n",
    "    pred_folder = \"Cellpose_UnTuned folder\"\n",
    "    cellpose_unTuned_metrics_dict[i] = process_image_folder(pred_folder, gt_folder,i)\n",
    "    print(f\"Cellpose  Untuned: {cellpose_unTuned_metrics_dict[i]}\")\n",
    "\n",
    "    pred_folder = \"QuPath_RF folder\"\n",
    "    QuPath_RF_metrics_dict[i] = process_image_folder(pred_folder, gt_folder,i)\n",
    "    print(f\"QuPath RF: {QuPath_RF_metrics_dict[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of the code is just to combine the results from all the images and save the output accordingly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dict = dict()\n",
    "def combine_dicts(dict1, dict2):\n",
    "    combined_dict = {}\n",
    "\n",
    "    # Iterate through the keys in the first dictionary\n",
    "    for key in dict1:\n",
    "        if key in dict2:\n",
    "            combined_dict[key] = dict1[key] + dict2[key]\n",
    "        else:\n",
    "            combined_dict[key] = dict1[key]\n",
    "\n",
    "    # Add the keys from the second dictionary that are not in the first dictionary\n",
    "    for key in dict2:\n",
    "        if key not in combined_dict:\n",
    "            combined_dict[key] = dict2[key]\n",
    "\n",
    "    combined_dict['accuracy'] = combined_dict['accuracy'] / 2 \n",
    "    combined_dict['precision'] = combined_dict['precision'] / 2 \n",
    "    combined_dict['recall'] = combined_dict['recall'] / 2 \n",
    "    combined_dict['f1_score'] = combined_dict['f1_score'] / 2 \n",
    "    return combined_dict\n",
    "\n",
    "final_dict[\"Cellpose_FineTuned\"] = combine_dicts(cellpose_fineTuned_metrics_dict[1], cellpose_fineTuned_metrics_dict[2])\n",
    "final_dict[\"Cellpose_UnTuned\"] = combine_dicts(cellpose_unTuned_metrics_dict[1], cellpose_unTuned_metrics_dict[2])\n",
    "final_dict[\"QuPath_RF\"] = combine_dicts(QuPath_RF_metrics_dict[1], QuPath_RF_metrics_dict[2])\n",
    "print(final_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def save_nested_dict_to_csv(nested_dict, csv_filename):\n",
    "    # Extract fieldnames from nested dictionaries\n",
    "    fieldnames = set()\n",
    "    for key, sub_dict in nested_dict.items():\n",
    "        fieldnames.update(sub_dict.keys())\n",
    "\n",
    "    # Add the top-level keys to the fieldnames\n",
    "    fieldnames = ['Method'] + list(fieldnames)\n",
    "\n",
    "    # Flatten the nested dictionary\n",
    "    rows = []\n",
    "    for key, sub_dict in nested_dict.items():\n",
    "        row = {'Method': key}\n",
    "        row.update(sub_dict)\n",
    "        rows.append(row)\n",
    "\n",
    "    # Write to CSV file\n",
    "    with open(csv_filename, 'w', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(rows)\n",
    "        \n",
    "# Save to CSV\n",
    "outpath = \"<path to output>\"\n",
    "save_nested_dict_to_csv(final_dict, outpath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
